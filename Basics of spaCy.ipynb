{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lei Lei\n",
    "\n",
    "Shanghai International Studies University\n",
    "\n",
    "leileicn@qq.com\n",
    "\n",
    "November 8, 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Basics of spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP tasks: tokenising, pos-tagging, lemmatising, syntactic parsing, ... \n",
    "\n",
    "NLP package: \n",
    "\n",
    "1. NLTK\n",
    "\n",
    "2. Stanford CoreNLP (Java; Stanza, Python)\n",
    "\n",
    "3. spaCy (Python), the state-of-art package of NLP tasks.\n",
    "\n",
    "   ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### What spaCy is\n",
    "- spaCy is \"a library for advanced Natural Language Processing in Python and Cython.\" \n",
    "- It is a tool developed for a number of tasks that are widely used in applied linguistics reseaerch such as sentence segmentation/splitting, tokenization, part-of-speech tagging (pos tagging), lemmatization, syntactic parsing, named entity recognition, word2vec/word embedding, etc.. \n",
    "\n",
    "### Features\n",
    "- Free, open source\n",
    "- Fast (\"Blazing fast\")\n",
    "- Supporting many languages (67+ languages in spaCy 3.2, November 2022)\n",
    "- Incorporaring multiple tasks: \"Components for named entity recognition, part-of-speech tagging, dependency parsing, sentence segmentation, text classification, lemmatization, morphological analysis, entity linking and more.\"\n",
    "- Integrating state-of-the-arts research (word2vec, sense2vec (a library for computing word similarities, based on Word2vec), deep learning with pretrained transformers like BERT ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Installaiton of spaCy\n",
    "- pip install -U pip setuptools wheel\n",
    "- pip install -U spacy\n",
    "\n",
    "# pip3 install ...\n",
    "\n",
    "#### Downloading pretrained models \n",
    "- python -m spacy download en_core_web_sm\n",
    "- python -m spacy download zh_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip3 install spacy\n",
    "\n",
    "- python -m spacy download en_core_web_sm\n",
    "- python -m spacy download en_core_web_md\n",
    "- python -m spacy download en_core_web_lg\n",
    "\n",
    "- python -m spacy download zh_core_web_sm\n",
    "- pip3 install jieba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip3 install spacy\n",
    "\n",
    "- python -m spacy download en_core_web_sm\n",
    "- python -m spacy download en_core_web_md\n",
    "- python -m spacy download en_core_web_lg\n",
    "\n",
    "- python -m spacy download zh_core_web_sm\n",
    "- pip3 install jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:51:52.634758Z",
     "start_time": "2024-11-07T11:51:52.624466Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # a lias\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Tokenization and pos-tagging with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the pretrained model: English tokenizer, tagger, parser\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# nlp = spacy.load('./en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test on sentences\n",
    "my_sents = \"spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.\"\n",
    "\n",
    "# my_sents = '''Research on incidental second language (L2) vocabulary acquisition through reading has claimed that repeated encounters with unfamiliar words and the relative elaboration of processing these words facilitate word learning. \n",
    "\n",
    "# However, so far both variables have been investigated in isolation. \n",
    "\n",
    "# To help close this research gap, the current study investigates the differential effects of the variables 'word exposure frequency' and 'elaboration of word processing' on the initial word learning and subsequent word retention of advanced learners of L2 English. Whereas results showed equal effects for both variables on initial word learning, subsequent word retention was more contingent on elaborate processing of form-meaning relationships than on word frequency. These results, together with those of the studies reviewed, suggest that processing words again after reading (input output cycles) is superior to reading-only tasks. The findings have significant implications for adaptation and development of teaching materials that enhance L2 vocabulary learning.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Processing the sents\n",
    "\n",
    "doc = nlp(my_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[spaCy is a free open-source library for Natural Language Processing in Python.,\n",
       " It features NER, POS tagging, dependency parsing, word vectors and more.]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence segmentation\n",
    "\n",
    "# for sent in doc.sents:\n",
    "#     print('->', sent)\n",
    "\n",
    "my_sents = [sent for sent in doc.sents]\n",
    "my_sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy spacy INTJ UH\n",
      "is be AUX VBZ\n",
      "a a DET DT\n",
      "free free ADJ JJ\n",
      "open open ADJ JJ\n",
      "- - PUNCT HYPH\n",
      "source source NOUN NN\n",
      "library library NOUN NN\n",
      "for for ADP IN\n",
      "Natural Natural PROPN NNP\n",
      "Language Language PROPN NNP\n",
      "Processing Processing PROPN NNP\n",
      "in in ADP IN\n",
      "Python Python PROPN NNP\n",
      ". . PUNCT .\n",
      "It it PRON PRP\n",
      "features feature VERB VBZ\n",
      "NER NER PROPN NNP\n",
      ", , PUNCT ,\n",
      "POS POS PROPN NNP\n",
      "tagging tagging NOUN NN\n",
      ", , PUNCT ,\n",
      "dependency dependency NOUN NN\n",
      "parsing parsing NOUN NN\n",
      ", , PUNCT ,\n",
      "word word NOUN NN\n",
      "vectors vector NOUN NNS\n",
      "and and CCONJ CC\n",
      "more more ADJ JJR\n",
      ". . PUNCT .\n"
     ]
    }
   ],
   "source": [
    "# Check out the tokens, lemmas, and part-of-speech tags\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Storing the results in a DataFrame\n",
    "#### Method 1\n",
    "\n",
    "- store tokens, lemmas, pos_tags in lists\n",
    "- obtain a DataFrame with the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokens_list = []\n",
    "lemmas_list = []\n",
    "pos_list = []\n",
    "tag_list = []\n",
    "\n",
    "mydf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "\n",
    "    tokens_list.append(token.text)\n",
    "    lemmas_list.append(token.lemma_)\n",
    "    pos_list.append(token.pos_)\n",
    "    tag_list.append(token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spaCy</td>\n",
       "      <td>spacy</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free</td>\n",
       "      <td>free</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open</td>\n",
       "      <td>open</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokens lemmas   pos  tag\n",
       "0  spaCy  spacy  INTJ   UH\n",
       "1     is     be   AUX  VBZ\n",
       "2      a      a   DET   DT\n",
       "3   free   free   ADJ   JJ\n",
       "4   open   open   ADJ   JJ"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf['tokens'] = tokens_list\n",
    "mydf['lemmas'] = lemmas_list\n",
    "mydf['pos'] = pos_list\n",
    "mydf['tag'] = tag_list\n",
    "\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Storing the results in a DataFrame\n",
    "#### Method 2\n",
    "\n",
    "- use list comprehension to store the tokens, lemmas, pos_tags in a list of lists\n",
    "- obtain the DataFrame with the list of lists\n",
    "- More efficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 'life'], [1, 'is'], [2, 'short'], [3, 'i'], [4, 'love'], [5, 'python']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list comprehension: returns a list, a list of lists\n",
    "# takes place of a for loop\n",
    "\n",
    "# mylist = []\n",
    "\n",
    "# for i in range(0, 10, 2):\n",
    "#     mylist.append(i)\n",
    "\n",
    "# print(mylist)\n",
    "\n",
    "# [i for i in range(0, 10, 2)]\n",
    "\n",
    "\n",
    "mylist = ['life', 'is', 'short', 'i', 'love', 'python']\n",
    "\n",
    "# enumerate(), returns: id, item\n",
    "\n",
    "# mylist2 = []\n",
    "\n",
    "# for id, token in enumerate(mylist):\n",
    "#     mylist2.append([id, token])\n",
    "#     # mylist2.append((id, token))\n",
    "\n",
    "# mylist2 \n",
    "\n",
    "[[id, token] for id, token in enumerate(mylist)]\n",
    "\n",
    "# list, tuple: container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spaCy', 'spacy', 'INTJ', 'UH'],\n",
       " ['is', 'be', 'AUX', 'VBZ'],\n",
       " ['a', 'a', 'DET', 'DT'],\n",
       " ['free', 'free', 'ADJ', 'JJ'],\n",
       " ['open', 'open', 'ADJ', 'JJ'],\n",
       " ['-', '-', 'PUNCT', 'HYPH'],\n",
       " ['source', 'source', 'NOUN', 'NN'],\n",
       " ['library', 'library', 'NOUN', 'NN'],\n",
       " ['for', 'for', 'ADP', 'IN'],\n",
       " ['Natural', 'Natural', 'PROPN', 'NNP'],\n",
       " ['Language', 'Language', 'PROPN', 'NNP'],\n",
       " ['Processing', 'Processing', 'PROPN', 'NNP'],\n",
       " ['in', 'in', 'ADP', 'IN'],\n",
       " ['Python', 'Python', 'PROPN', 'NNP'],\n",
       " ['.', '.', 'PUNCT', '.'],\n",
       " ['It', 'it', 'PRON', 'PRP'],\n",
       " ['features', 'feature', 'VERB', 'VBZ'],\n",
       " ['NER', 'NER', 'PROPN', 'NNP'],\n",
       " [',', ',', 'PUNCT', ','],\n",
       " ['POS', 'POS', 'PROPN', 'NNP'],\n",
       " ['tagging', 'tagging', 'NOUN', 'NN'],\n",
       " [',', ',', 'PUNCT', ','],\n",
       " ['dependency', 'dependency', 'NOUN', 'NN'],\n",
       " ['parsing', 'parsing', 'NOUN', 'NN'],\n",
       " [',', ',', 'PUNCT', ','],\n",
       " ['word', 'word', 'NOUN', 'NN'],\n",
       " ['vectors', 'vector', 'NOUN', 'NNS'],\n",
       " ['and', 'and', 'CCONJ', 'CC'],\n",
       " ['more', 'more', 'ADJ', 'JJR'],\n",
       " ['.', '.', 'PUNCT', '.']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[token.text, token.lemma_, token.pos_, token.tag_] for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_of_lists = [[token.text, token.lemma_, token.pos_, token.tag_] for token in doc]\n",
    "list_of_columns = ['tokens', 'lemmas', 'pos', 'tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mydf2 = pd.DataFrame(list_of_lists, columns= list_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spaCy</td>\n",
       "      <td>spacy</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free</td>\n",
       "      <td>free</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open</td>\n",
       "      <td>open</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokens lemmas   pos  tag\n",
       "0  spaCy  spacy  INTJ   UH\n",
       "1     is     be   AUX  VBZ\n",
       "2      a      a   DET   DT\n",
       "3   free   free   ADJ   JJ\n",
       "4   open   open   ADJ   JJ"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   },
   "source": [
    "## 2. Dependency parsing with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the pretrained model: English tokenizer, tagger, parser\n",
    "\n",
    "# i love python.\n",
    "# good boy, adj + n, adj to modifiy the noun \n",
    "# governor/head, dependent, \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test on sentences\n",
    "my_sents = \"spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Processing the sents\n",
    "\n",
    "doc = nlp(my_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy spacy nsubj nominal subject is be\n",
      "is be ROOT root is be\n",
      "a a det determiner library library\n",
      "free free amod adjectival modifier library library\n",
      "open open amod adjectival modifier source source\n",
      "- - punct punctuation source source\n",
      "source source compound compound library library\n",
      "library library attr attribute is be\n",
      "for for prep prepositional modifier library library\n",
      "Natural Natural compound compound Language Language\n",
      "Language Language compound compound Processing Processing\n",
      "Processing Processing pobj object of preposition for for\n",
      "in in prep prepositional modifier Processing Processing\n",
      "Python Python pobj object of preposition in in\n",
      ". . punct punctuation is be\n",
      "It it nsubj nominal subject features feature\n",
      "features feature ROOT root features feature\n",
      "NER NER dobj direct object features feature\n",
      ", , punct punctuation NER NER\n",
      "POS POS compound compound tagging tagging\n",
      "tagging tagging conj conjunct NER NER\n",
      ", , punct punctuation tagging tagging\n",
      "dependency dependency compound compound parsing parsing\n",
      "parsing parsing conj conjunct tagging tagging\n",
      ", , punct punctuation parsing parsing\n",
      "word word compound compound vectors vector\n",
      "vectors vector conj conjunct parsing parsing\n",
      "and and cc coordinating conjunction vectors vector\n",
      "more more conj conjunct vectors vector\n",
      ". . punct punctuation features feature\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    # token.dep_ : dep. relation \n",
    "    # token.head.text ï¼šhead token\n",
    "    # token.head.lemma_ : head lemma\n",
    "    # token.head.pos_\n",
    "    # token.head.tag_\n",
    "    # spacy.explain(token.dep_)\n",
    "    \n",
    "    print(token.text, token.lemma_, token.dep_, spacy.explain(token.dep_), token.head.text, token.head.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spaCy', 'spacy', 'nsubj', 'nominal subject', 'is', 'be'],\n",
       " ['is', 'be', 'ROOT', 'root', 'is', 'be'],\n",
       " ['a', 'a', 'det', 'determiner', 'library', 'library'],\n",
       " ['free', 'free', 'amod', 'adjectival modifier', 'library', 'library'],\n",
       " ['open', 'open', 'amod', 'adjectival modifier', 'source', 'source'],\n",
       " ['-', '-', 'punct', 'punctuation', 'source', 'source'],\n",
       " ['source', 'source', 'compound', 'compound', 'library', 'library'],\n",
       " ['library', 'library', 'attr', 'attribute', 'is', 'be'],\n",
       " ['for', 'for', 'prep', 'prepositional modifier', 'library', 'library'],\n",
       " ['Natural', 'Natural', 'compound', 'compound', 'Language', 'Language'],\n",
       " ['Language', 'Language', 'compound', 'compound', 'Processing', 'Processing'],\n",
       " ['Processing', 'Processing', 'pobj', 'object of preposition', 'for', 'for'],\n",
       " ['in', 'in', 'prep', 'prepositional modifier', 'Processing', 'Processing'],\n",
       " ['Python', 'Python', 'pobj', 'object of preposition', 'in', 'in'],\n",
       " ['.', '.', 'punct', 'punctuation', 'is', 'be'],\n",
       " ['It', 'it', 'nsubj', 'nominal subject', 'features', 'feature'],\n",
       " ['features', 'feature', 'ROOT', 'root', 'features', 'feature'],\n",
       " ['NER', 'NER', 'dobj', 'direct object', 'features', 'feature'],\n",
       " [',', ',', 'punct', 'punctuation', 'NER', 'NER'],\n",
       " ['POS', 'POS', 'compound', 'compound', 'tagging', 'tagging'],\n",
       " ['tagging', 'tagging', 'conj', 'conjunct', 'NER', 'NER'],\n",
       " [',', ',', 'punct', 'punctuation', 'tagging', 'tagging'],\n",
       " ['dependency', 'dependency', 'compound', 'compound', 'parsing', 'parsing'],\n",
       " ['parsing', 'parsing', 'conj', 'conjunct', 'tagging', 'tagging'],\n",
       " [',', ',', 'punct', 'punctuation', 'parsing', 'parsing'],\n",
       " ['word', 'word', 'compound', 'compound', 'vectors', 'vector'],\n",
       " ['vectors', 'vector', 'conj', 'conjunct', 'parsing', 'parsing'],\n",
       " ['and', 'and', 'cc', 'coordinating conjunction', 'vectors', 'vector'],\n",
       " ['more', 'more', 'conj', 'conjunct', 'vectors', 'vector'],\n",
       " ['.', '.', 'punct', 'punctuation', 'features', 'feature']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[token.text, token.lemma_, token.dep_, spacy.explain(token.dep_), token.head.text, token.head.lemma_] for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy is nsubj -> nominal subject\n",
      "is is ROOT -> root\n",
      "a library det -> determiner\n",
      "free library amod -> adjectival modifier\n",
      "open source amod -> adjectival modifier\n",
      "- source punct -> punctuation\n",
      "source library compound -> compound\n",
      "library is attr -> attribute\n",
      "for library prep -> prepositional modifier\n",
      "Natural Language compound -> compound\n",
      "Language Processing compound -> compound\n",
      "Processing for pobj -> object of preposition\n",
      "in Processing prep -> prepositional modifier\n",
      "Python in pobj -> object of preposition\n",
      ". is punct -> punctuation\n",
      "It features nsubj -> nominal subject\n",
      "features features ROOT -> root\n",
      "NER features dobj -> direct object\n",
      ", NER punct -> punctuation\n",
      "POS tagging compound -> compound\n",
      "tagging NER conj -> conjunct\n",
      ", tagging punct -> punctuation\n",
      "dependency parsing compound -> compound\n",
      "parsing tagging conj -> conjunct\n",
      ", parsing punct -> punctuation\n",
      "word vectors compound -> compound\n",
      "vectors parsing conj -> conjunct\n",
      "and vectors cc -> coordinating conjunction\n",
      "more vectors conj -> conjunct\n",
      ". features punct -> punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.head.text, token.dep_, '->', spacy.explain(token.dep_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting word position id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spaCy', 0, 'nsubj', 'is', 1],\n",
       " ['is', 1, 'ROOT', 'is', 1],\n",
       " ['a', 2, 'det', 'library', 7],\n",
       " ['free', 3, 'amod', 'library', 7],\n",
       " ['open', 4, 'amod', 'source', 6],\n",
       " ['-', 5, 'punct', 'source', 6],\n",
       " ['source', 6, 'compound', 'library', 7],\n",
       " ['library', 7, 'attr', 'is', 1],\n",
       " ['for', 8, 'prep', 'library', 7],\n",
       " ['Natural', 9, 'compound', 'Language', 10],\n",
       " ['Language', 10, 'compound', 'Processing', 11],\n",
       " ['Processing', 11, 'pobj', 'for', 8],\n",
       " ['in', 12, 'prep', 'Processing', 11],\n",
       " ['Python', 13, 'pobj', 'in', 12],\n",
       " ['.', 14, 'punct', 'is', 1],\n",
       " ['It', 15, 'nsubj', 'features', 16],\n",
       " ['features', 16, 'ROOT', 'features', 16],\n",
       " ['NER', 17, 'dobj', 'features', 16],\n",
       " [',', 18, 'punct', 'NER', 17],\n",
       " ['POS', 19, 'compound', 'tagging', 20],\n",
       " ['tagging', 20, 'conj', 'NER', 17],\n",
       " [',', 21, 'punct', 'tagging', 20],\n",
       " ['dependency', 22, 'compound', 'parsing', 23],\n",
       " ['parsing', 23, 'conj', 'tagging', 20],\n",
       " [',', 24, 'punct', 'parsing', 23],\n",
       " ['word', 25, 'compound', 'vectors', 26],\n",
       " ['vectors', 26, 'conj', 'parsing', 23],\n",
       " ['and', 27, 'cc', 'vectors', 26],\n",
       " ['more', 28, 'conj', 'vectors', 26],\n",
       " ['.', 29, 'punct', 'features', 16]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependency distance\n",
    "# token.i\n",
    "# token.head.i\n",
    "\n",
    "# for token in doc:\n",
    "#     print(token.text, token.i, '->', token.dep_, '->', token.head.text, token.head.i)\n",
    "        \n",
    "[[token.text, token.i, token.dep_, token.head.text, token.head.i] for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapping all up in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [[token.text, token.i, token.lemma_, token.pos_, token.tag_, token.dep_, token.head.text, token.head.i, token.head.lemma_, token.head.pos_, token.head.tag_] for token in doc]\n",
    "\n",
    "list_of_columns = ['token', 'token_id', 'lemma', 'pos', 'tag', 'dep_relation', 'head_token', 'head_token_id', 'head_lemma', 'head_pos', 'head_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf3 = pd.DataFrame(list_of_lists, columns = list_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep_relation</th>\n",
       "      <th>head_token</th>\n",
       "      <th>head_token_id</th>\n",
       "      <th>head_lemma</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>head_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spaCy</td>\n",
       "      <td>0</td>\n",
       "      <td>spacy</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>library</td>\n",
       "      <td>7</td>\n",
       "      <td>library</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free</td>\n",
       "      <td>3</td>\n",
       "      <td>free</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>library</td>\n",
       "      <td>7</td>\n",
       "      <td>library</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open</td>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>source</td>\n",
       "      <td>6</td>\n",
       "      <td>source</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  token_id  lemma   pos  tag dep_relation head_token  head_token_id  \\\n",
       "0  spaCy         0  spacy  INTJ   UH        nsubj         is              1   \n",
       "1     is         1     be   AUX  VBZ         ROOT         is              1   \n",
       "2      a         2      a   DET   DT          det    library              7   \n",
       "3   free         3   free   ADJ   JJ         amod    library              7   \n",
       "4   open         4   open   ADJ   JJ         amod     source              6   \n",
       "\n",
       "  head_lemma head_pos head_tag  \n",
       "0         be      AUX      VBZ  \n",
       "1         be      AUX      VBZ  \n",
       "2    library     NOUN       NN  \n",
       "3    library     NOUN       NN  \n",
       "4     source     NOUN       NN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faciliating the processing steps with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(mystr):\n",
    "        doc = nlp(mystr)\n",
    "        \n",
    "        mylist = [[t.text, t.i, t.lemma_, t.pos_, t.tag_, t.dep_, spacy.explain(t.dep_), t.head.text, t.head.i, t.head.lemma_, t.head.pos_, t.head.tag_] for t in doc]\n",
    "        \n",
    "        mycolumns = ['token', 'token_id', 'token_lemma', 'token_pos', 'token_tag', 'dep', 'dep_explanation', 'head', 'head_id','head_lemma', 'head_pos', 'head_tag']\n",
    "        \n",
    "        mydf = pd.DataFrame(mylist, columns = mycolumns)\n",
    "        \n",
    "        return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sents = \"spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>token_tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>dep_explanation</th>\n",
       "      <th>head</th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_lemma</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>head_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spaCy</td>\n",
       "      <td>0</td>\n",
       "      <td>spacy</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nominal subject</td>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>determiner</td>\n",
       "      <td>library</td>\n",
       "      <td>7</td>\n",
       "      <td>library</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free</td>\n",
       "      <td>3</td>\n",
       "      <td>free</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>adjectival modifier</td>\n",
       "      <td>library</td>\n",
       "      <td>7</td>\n",
       "      <td>library</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open</td>\n",
       "      <td>4</td>\n",
       "      <td>open</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>adjectival modifier</td>\n",
       "      <td>source</td>\n",
       "      <td>6</td>\n",
       "      <td>source</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>source</td>\n",
       "      <td>6</td>\n",
       "      <td>source</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>source</td>\n",
       "      <td>6</td>\n",
       "      <td>source</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>compound</td>\n",
       "      <td>library</td>\n",
       "      <td>7</td>\n",
       "      <td>library</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>library</td>\n",
       "      <td>7</td>\n",
       "      <td>library</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>attr</td>\n",
       "      <td>attribute</td>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>8</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>prepositional modifier</td>\n",
       "      <td>library</td>\n",
       "      <td>7</td>\n",
       "      <td>library</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Natural</td>\n",
       "      <td>9</td>\n",
       "      <td>Natural</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>compound</td>\n",
       "      <td>Language</td>\n",
       "      <td>10</td>\n",
       "      <td>Language</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Language</td>\n",
       "      <td>10</td>\n",
       "      <td>Language</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>compound</td>\n",
       "      <td>Processing</td>\n",
       "      <td>11</td>\n",
       "      <td>Processing</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Processing</td>\n",
       "      <td>11</td>\n",
       "      <td>Processing</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>object of preposition</td>\n",
       "      <td>for</td>\n",
       "      <td>8</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>in</td>\n",
       "      <td>12</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>prepositional modifier</td>\n",
       "      <td>Processing</td>\n",
       "      <td>11</td>\n",
       "      <td>Processing</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Python</td>\n",
       "      <td>13</td>\n",
       "      <td>Python</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>object of preposition</td>\n",
       "      <td>in</td>\n",
       "      <td>12</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>14</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>It</td>\n",
       "      <td>15</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nominal subject</td>\n",
       "      <td>features</td>\n",
       "      <td>16</td>\n",
       "      <td>feature</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>features</td>\n",
       "      <td>16</td>\n",
       "      <td>feature</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>features</td>\n",
       "      <td>16</td>\n",
       "      <td>feature</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NER</td>\n",
       "      <td>17</td>\n",
       "      <td>NER</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>dobj</td>\n",
       "      <td>direct object</td>\n",
       "      <td>features</td>\n",
       "      <td>16</td>\n",
       "      <td>feature</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>,</td>\n",
       "      <td>18</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>NER</td>\n",
       "      <td>17</td>\n",
       "      <td>NER</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>POS</td>\n",
       "      <td>19</td>\n",
       "      <td>POS</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>compound</td>\n",
       "      <td>tagging</td>\n",
       "      <td>20</td>\n",
       "      <td>tagging</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tagging</td>\n",
       "      <td>20</td>\n",
       "      <td>tagging</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>conj</td>\n",
       "      <td>conjunct</td>\n",
       "      <td>NER</td>\n",
       "      <td>17</td>\n",
       "      <td>NER</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>,</td>\n",
       "      <td>21</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>tagging</td>\n",
       "      <td>20</td>\n",
       "      <td>tagging</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dependency</td>\n",
       "      <td>22</td>\n",
       "      <td>dependency</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>compound</td>\n",
       "      <td>parsing</td>\n",
       "      <td>23</td>\n",
       "      <td>parsing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>parsing</td>\n",
       "      <td>23</td>\n",
       "      <td>parsing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>conj</td>\n",
       "      <td>conjunct</td>\n",
       "      <td>tagging</td>\n",
       "      <td>20</td>\n",
       "      <td>tagging</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>,</td>\n",
       "      <td>24</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>parsing</td>\n",
       "      <td>23</td>\n",
       "      <td>parsing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>word</td>\n",
       "      <td>25</td>\n",
       "      <td>word</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>compound</td>\n",
       "      <td>vectors</td>\n",
       "      <td>26</td>\n",
       "      <td>vector</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vectors</td>\n",
       "      <td>26</td>\n",
       "      <td>vector</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>conj</td>\n",
       "      <td>conjunct</td>\n",
       "      <td>parsing</td>\n",
       "      <td>23</td>\n",
       "      <td>parsing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>and</td>\n",
       "      <td>27</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>coordinating conjunction</td>\n",
       "      <td>vectors</td>\n",
       "      <td>26</td>\n",
       "      <td>vector</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>more</td>\n",
       "      <td>28</td>\n",
       "      <td>more</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJR</td>\n",
       "      <td>conj</td>\n",
       "      <td>conjunct</td>\n",
       "      <td>vectors</td>\n",
       "      <td>26</td>\n",
       "      <td>vector</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>.</td>\n",
       "      <td>29</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>features</td>\n",
       "      <td>16</td>\n",
       "      <td>feature</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  token_id token_lemma token_pos token_tag       dep  \\\n",
       "0        spaCy         0       spacy      INTJ        UH     nsubj   \n",
       "1           is         1          be       AUX       VBZ      ROOT   \n",
       "2            a         2           a       DET        DT       det   \n",
       "3         free         3        free       ADJ        JJ      amod   \n",
       "4         open         4        open       ADJ        JJ      amod   \n",
       "5            -         5           -     PUNCT      HYPH     punct   \n",
       "6       source         6      source      NOUN        NN  compound   \n",
       "7      library         7     library      NOUN        NN      attr   \n",
       "8          for         8         for       ADP        IN      prep   \n",
       "9      Natural         9     Natural     PROPN       NNP  compound   \n",
       "10    Language        10    Language     PROPN       NNP  compound   \n",
       "11  Processing        11  Processing     PROPN       NNP      pobj   \n",
       "12          in        12          in       ADP        IN      prep   \n",
       "13      Python        13      Python     PROPN       NNP      pobj   \n",
       "14           .        14           .     PUNCT         .     punct   \n",
       "15          It        15          it      PRON       PRP     nsubj   \n",
       "16    features        16     feature      VERB       VBZ      ROOT   \n",
       "17         NER        17         NER     PROPN       NNP      dobj   \n",
       "18           ,        18           ,     PUNCT         ,     punct   \n",
       "19         POS        19         POS     PROPN       NNP  compound   \n",
       "20     tagging        20     tagging      NOUN        NN      conj   \n",
       "21           ,        21           ,     PUNCT         ,     punct   \n",
       "22  dependency        22  dependency      NOUN        NN  compound   \n",
       "23     parsing        23     parsing      NOUN        NN      conj   \n",
       "24           ,        24           ,     PUNCT         ,     punct   \n",
       "25        word        25        word      NOUN        NN  compound   \n",
       "26     vectors        26      vector      NOUN       NNS      conj   \n",
       "27         and        27         and     CCONJ        CC        cc   \n",
       "28        more        28        more       ADJ       JJR      conj   \n",
       "29           .        29           .     PUNCT         .     punct   \n",
       "\n",
       "             dep_explanation        head  head_id  head_lemma head_pos  \\\n",
       "0            nominal subject          is        1          be      AUX   \n",
       "1                       root          is        1          be      AUX   \n",
       "2                 determiner     library        7     library     NOUN   \n",
       "3        adjectival modifier     library        7     library     NOUN   \n",
       "4        adjectival modifier      source        6      source     NOUN   \n",
       "5                punctuation      source        6      source     NOUN   \n",
       "6                   compound     library        7     library     NOUN   \n",
       "7                  attribute          is        1          be      AUX   \n",
       "8     prepositional modifier     library        7     library     NOUN   \n",
       "9                   compound    Language       10    Language    PROPN   \n",
       "10                  compound  Processing       11  Processing    PROPN   \n",
       "11     object of preposition         for        8         for      ADP   \n",
       "12    prepositional modifier  Processing       11  Processing    PROPN   \n",
       "13     object of preposition          in       12          in      ADP   \n",
       "14               punctuation          is        1          be      AUX   \n",
       "15           nominal subject    features       16     feature     VERB   \n",
       "16                      root    features       16     feature     VERB   \n",
       "17             direct object    features       16     feature     VERB   \n",
       "18               punctuation         NER       17         NER    PROPN   \n",
       "19                  compound     tagging       20     tagging     NOUN   \n",
       "20                  conjunct         NER       17         NER    PROPN   \n",
       "21               punctuation     tagging       20     tagging     NOUN   \n",
       "22                  compound     parsing       23     parsing     NOUN   \n",
       "23                  conjunct     tagging       20     tagging     NOUN   \n",
       "24               punctuation     parsing       23     parsing     NOUN   \n",
       "25                  compound     vectors       26      vector     NOUN   \n",
       "26                  conjunct     parsing       23     parsing     NOUN   \n",
       "27  coordinating conjunction     vectors       26      vector     NOUN   \n",
       "28                  conjunct     vectors       26      vector     NOUN   \n",
       "29               punctuation    features       16     feature     VERB   \n",
       "\n",
       "   head_tag  \n",
       "0       VBZ  \n",
       "1       VBZ  \n",
       "2        NN  \n",
       "3        NN  \n",
       "4        NN  \n",
       "5        NN  \n",
       "6        NN  \n",
       "7       VBZ  \n",
       "8        NN  \n",
       "9       NNP  \n",
       "10      NNP  \n",
       "11       IN  \n",
       "12      NNP  \n",
       "13       IN  \n",
       "14      VBZ  \n",
       "15      VBZ  \n",
       "16      VBZ  \n",
       "17      VBZ  \n",
       "18      NNP  \n",
       "19       NN  \n",
       "20      NNP  \n",
       "21       NN  \n",
       "22       NN  \n",
       "23       NN  \n",
       "24       NN  \n",
       "25      NNS  \n",
       "26       NN  \n",
       "27      NNS  \n",
       "28      NNS  \n",
       "29      VBZ  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_parse(my_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "117px",
    "width": "454px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "7ea45a68df6c081ed75564725b0d139197db1d4205c00e9c49160b50bc65c42b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
